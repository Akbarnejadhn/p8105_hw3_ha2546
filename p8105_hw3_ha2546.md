p8105\_hw3\_ha2546
================
Hana Akbarnejad
10/9/2019

``` r
# set.seed(5)
# random_sample = instacart %>% 
#   filter(
#   sample(pull(instacart, order_id))
#   )
```

In the first problem, we are interested in exploring the *instacart*
dataset. This dataset stores information about online grocery shopping
from 2017. The datset contains 1384617 observations of 131209 unique
orders of 39123 differennt products. There are 15 variables associated
with these rows such as *order\_dow* (the day of the week that the order
has been placed), *order\_hour\_of\_day* (the time of the day that the
order has been placed), *product\_name* (the item purchased), *aisle*
(the aisle that the item has chosen from), etc. We can take differenvt
samples from this dataset.

## Problem1

How many aisles are there, and which aisles are the most items ordered
from? I grouped the dtaset by the aisles, and understood that there are
total of 134 different isles. Then I counted the number of times items
have been ordered from each isle. By further arranging this column in
descending order, I found the most popular isles. Top five aisles with
the most items ordered from are fresh vegetables, fresh fruits, packaged
vegetable fruits, yogurt, packaged cheese.I then made a plot that shows
the number of items ordered in each aisle (only for aisles with more
than 10000 items ordered). For this purpose I made a bar plot that shows
the aisle names on x axis and the number of items ordered on y axis.

``` r
aisle_fav_n = instacart %>% 
  # group_by(aisle) %>% 
  count(aisle, name = "aisle_order_n") %>% 
  arrange(desc(aisle_order_n))

aisle_fav_plot = aisle_fav_n %>% 
  filter(aisle_order_n > 10000) %>% 
  ggplot(aes(x = reorder(aisle, -aisle_order_n), y = aisle_order_n)) +
  geom_bar(stat="identity", width=0.5, fill="blue") +
  theme(axis.text.x = element_text(angle = 80, hjust = 1)) +
  labs(
    title = "Number of Orders in Favorite Aisles",
    x = "Aisle name",
    y = "Number of orders",
    caption = "Plot 1"
  )

aisle_fav_n
```

    ## # A tibble: 134 x 2
    ##    aisle                         aisle_order_n
    ##    <chr>                                 <int>
    ##  1 fresh vegetables                     150609
    ##  2 fresh fruits                         150473
    ##  3 packaged vegetables fruits            78493
    ##  4 yogurt                                55240
    ##  5 packaged cheese                       41699
    ##  6 water seltzer sparkling water         36617
    ##  7 milk                                  32644
    ##  8 chips pretzels                        31269
    ##  9 soy lactosefree                       26240
    ## 10 bread                                 23635
    ## # ... with 124 more rows

``` r
aisle_fav_plot
```

<img src="p8105_hw3_ha2546_files/figure-gfm/instacart-1.png" width="90%" />

``` r
top3_items = instacart %>% 
  filter(aisle == c("baking ingredients", "dog food care", "packaged vegetables fruits")) %>% 
  group_by(aisle, product_name) %>%
  summarize(
    count = n()
    ) %>% 
  top_n(3, count) %>% 
  knitr::kable()
```

In this part,

``` r
hours_days_products = instacart %>% 
  filter(product_name == c("Pink Lady Apples", "Coffee Ice Cream")) %>% 
  group_by(product_name, order_dow) %>% 
  summarize(
    hours_mean = mean(order_hour_of_day)
  ) %>% 
  pivot_wider(
    names_from = order_dow,
    values_from = hours_mean
  ) %>%
    rename(
      Sun = `0`, Mon = `1`, Tue = `2`, Wed = `3`, Thr = `4`, Fri = `5`, Sat = `6`
      ) %>% 
  knitr::kable(digits = 1)
```

## Problem 2

In this part, I worked with *BRFSS* dataset. First, I cleaned the names
and made a subset of the data which is focused on the *Overall Health*,
then I transformed response levels as ordered factors from poor to
excellent.

``` r
data("brfss_smart2010") 

brfss_data = brfss_smart2010 %>% 
  janitor::clean_names() %>% 
  filter(topic == "Overall Health") %>% 
  mutate(
    response = factor(response, levels = c("Poor", "Fair", "Good", "Very good", "Excellent"), ordered = TRUE)
  )
```

On the next step, I needed to know which states has more or equal than 7
locations in both 2002 and 20010.

``` r
brfss_location_2002 = brfss_data %>%
  filter(year == "2002") %>% 
  group_by(locationabbr) %>% 
  summarize(
    distinct_location = n_distinct(locationdesc)
    ) %>% 
  filter(distinct_location >= 7)


brfss_location_2010 = brfss_data %>%
  filter(year == "2010") %>% 
  group_by(locationabbr) %>% 
  summarize(
    distinct_location = n_distinct(locationdesc)
    ) %>% 
  filter(distinct_location >= 7)
```

We observed that during 2002, there were 6 locations satissfying this
condition, and during 2010 this number was 14.

In this part, I made a subset of data from excellent responses, then I
summarized the mean of the data\_value variable in different US states
and then made a spagetti plot of the mean crude prevalence percentage
(*data\_value*) against different years.

``` r
  brfss_exc = brfss_data %>%
  filter(
    response == "Excellent"
  ) %>%
  group_by(locationabbr, year) %>%
  summarize(
    mean_exc_location = mean(data_value)
  )

brfss_exc_spagetti = brfss_exc %>% 
  ggplot(aes(x = year, y = mean_exc_location, color = locationabbr)) +
  geom_line() +
    labs(
    title = "Mean Prevalence 2002 - 2010 among US States",
    x = "Year",
    y = "Mean Prevalence (%)",
    caption = "From BRFSS Excellent Responses")

brfss_exc_spagetti + labs(color = "STATES")
```

<img src="p8105_hw3_ha2546_files/figure-gfm/unnamed-chunk-4-1.png" width="90%" />

2010, distribution of data\_value for responses (“Poor” to “Excellent”)
among locations in NY State

``` r
library("patchwork")

graph_2006 = brfss_data %>%
  filter(
    year == "2006",
    locationabbr == "NY"
  ) %>%
  group_by(locationdesc) %>%
  ggplot(aes(x = response, y = data_value)) +
  geom_point(aes(color = locationdesc), alpha = .5) +
  geom_line()
  labs(
    title = "Distribution of Data Values - 2006",
    x = "Response Level",
    y = "Data Value",
    caption = NULL
  ) +
  theme_classic() +
  theme(legend.position = "bottom")
```

    ## NULL

``` r
graph_2010 = brfss_data %>%
  filter(
    year == "2010",
    locationabbr == "NY"
  ) %>%
  group_by(locationdesc) %>%
  ggplot(aes(x = response, y = data_value)) +
  geom_bar(stat="identity", width=0.5, aes(color = response), alpha = .5) +
  labs(
    title = "Distribution of Data Values-2010",
    x = "Response Level",
    y = "Data Value",
    caption = NULL
  ) +
  facet_grid(. ~ locationdesc)
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  theme(legend.position = "bottom")
```

    ## List of 2
    ##  $ axis.text.x    :List of 11
    ##   ..$ family       : NULL
    ##   ..$ face         : NULL
    ##   ..$ colour       : NULL
    ##   ..$ size         : NULL
    ##   ..$ hjust        : num 1
    ##   ..$ vjust        : NULL
    ##   ..$ angle        : num 90
    ##   ..$ lineheight   : NULL
    ##   ..$ margin       : NULL
    ##   ..$ debug        : NULL
    ##   ..$ inherit.blank: logi FALSE
    ##   ..- attr(*, "class")= chr [1:2] "element_text" "element"
    ##  $ legend.position: chr "bottom"
    ##  - attr(*, "class")= chr [1:2] "theme" "gg"
    ##  - attr(*, "complete")= logi FALSE
    ##  - attr(*, "validate")= logi TRUE

``` r
(graph_2006 / graph_2010)
```

<img src="p8105_hw3_ha2546_files/figure-gfm/unnamed-chunk-5-1.png" width="90%" />

## Problem 3
