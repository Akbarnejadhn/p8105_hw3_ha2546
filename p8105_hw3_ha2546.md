p8105\_hw3\_ha2546
================
Hana Akbarnejad
10/9/2019

``` r
# set.seed(5)
# random_sample = instacart %>%
#   filter(
#   sample(pull(instacart, order_id))
#   )
```

In the first problem, we are interested in exploring the *instacart*
dataset. This dataset stores information about online grocery shopping
from 2017. The datset contains 1384617 observations of 131209 unique
orders of 39123 differennt products. There are 15 variables associated
with these rows such as *order\_dow* (the day of the week that the order
has been placed), *order\_hour\_of\_day* (the time of the day that the
order has been placed), *product\_name* (the item purchased), *aisle*
(the aisle that the item has chosen from), etc. We can take differenvt
samples from this dataset.

## Problem1

How many aisles are there, and which aisles are the most items ordered
from? I grouped the dtaset by the aisles, and understood that there are
total of 134 different isles. Then I counted the number of times items
have been ordered from each isle. By further arranging this column in
descending order, I found the most popular isles. Top five aisles with
the most items ordered from are fresh vegetables, fresh fruits, packaged
vegetable fruits, yogurt, packaged cheese.I then made a plot that shows
the number of items ordered in each aisle (only for aisles with more
than 10000 items ordered). For this purpose I made a bar plot that shows
the aisle names on x axis and the number of items ordered on y axis.

``` r
aisle_fav_n = instacart %>% 
  # group_by(aisle) %>% 
  count(aisle, name = "aisle_order_n") %>% 
  arrange(desc(aisle_order_n))

aisle_fav_plot = aisle_fav_n %>% 
  filter(aisle_order_n > 10000) %>% 
  ggplot(aes(x = reorder(aisle, -aisle_order_n), y = aisle_order_n)) +
  geom_bar(stat="identity", width=0.5, fill="blue") +
  theme(axis.text.x = element_text(angle = 80, hjust = 1)) +
  labs(
    title = "Number of Orders in Favorite Aisles",
    x = "Aisle name",
    y = "Number of orders",
    caption = "Plot 1"
  )

aisle_fav_n
```

    ## # A tibble: 134 x 2
    ##    aisle                         aisle_order_n
    ##    <chr>                                 <int>
    ##  1 fresh vegetables                     150609
    ##  2 fresh fruits                         150473
    ##  3 packaged vegetables fruits            78493
    ##  4 yogurt                                55240
    ##  5 packaged cheese                       41699
    ##  6 water seltzer sparkling water         36617
    ##  7 milk                                  32644
    ##  8 chips pretzels                        31269
    ##  9 soy lactosefree                       26240
    ## 10 bread                                 23635
    ## # ... with 124 more rows

``` r
aisle_fav_plot
```

<img src="p8105_hw3_ha2546_files/figure-gfm/instacart-1.png" width="90%" />

``` r
top3_items = instacart %>% 
  filter(aisle == c("baking ingredients", "dog food care", "packaged vegetables fruits")) %>% 
  group_by(aisle, product_name) %>%
  summarize(
    count = n()
    ) %>% 
  top_n(3, count) %>% 
  knitr::kable()
```

In this part,

``` r
hours_days_products = instacart %>% 
  filter(product_name == c("Pink Lady Apples", "Coffee Ice Cream")) %>% 
  group_by(product_name, order_dow) %>% 
  summarize(
    hours_mean = mean(order_hour_of_day)
  ) %>% 
  pivot_wider(
    names_from = order_dow,
    values_from = hours_mean
  ) %>%
    rename(
      Sun = `0`, Mon = `1`, Tue = `2`, Wed = `3`, Thr = `4`, Fri = `5`, Sat = `6`
      ) %>% 
  knitr::kable(digits = 1)
```

## Problem 2

In this part, I worked with *BRFSS* dataset. First, I cleaned the names
and made a subset of the data which is focused on the *Overall Health*,
then I transformed response levels as ordered factors from poor to
excellent.

``` r
data("brfss_smart2010") 

brfss_data = brfss_smart2010 %>% 
  janitor::clean_names() %>% 
  filter(topic == "Overall Health") %>% 
  mutate(
    response = factor(response, levels = c("Poor", "Fair", "Good", "Very good", "Excellent"), ordered = TRUE)
  )
```

On the next step, I needed to know which states has more or equal than 7
locations in both 2002 and 20010.

``` r
brfss_location_2002 = brfss_data %>%
  filter(year == "2002") %>% 
  group_by(locationabbr) %>% 
  summarize(
    distinct_location = n_distinct(locationdesc)
    ) %>% 
  filter(distinct_location >= 7)


brfss_location_2010 = brfss_data %>%
  filter(year == "2010") %>% 
  group_by(locationabbr) %>% 
  summarize(
    distinct_location = n_distinct(locationdesc)
    ) %>% 
  filter(distinct_location >= 7)
```

We observed that during 2002, there were 6 locations satissfying this
condition, and during 2010 this number was 14.

In this part, I made a subset of data from excellent responses, then I
summarized the mean of the data\_value variable in different US states
and then made a spagetti plot that shows the mean of crude prevalence
percentage ( *data\_value* ) against different years.

``` r
  brfss_exc = brfss_data %>%
  filter(
    response == "Excellent"
  ) %>%
  group_by(locationabbr, year) %>%
  summarize(
    mean_exc_location = mean(data_value)
  )

brfss_exc_spagetti = brfss_exc %>% 
  ggplot(aes(x = year, y = mean_exc_location, color = locationabbr)) +
  geom_line() +
    labs(
    title = "Average Crude Prevalence 2002 - 2010 among US States",
    x = "Year",
    y = "Average Crude Prevalence (%)",
    caption = "From BRFSS Excellent Responses")

brfss_exc_spagetti + labs(color = "STATES")
```

<img src="p8105_hw3_ha2546_files/figure-gfm/unnamed-chunk-4-1.png" width="90%" />

In this part, I made a panel plot for the data from 2006 and 2010,
focusing on the distribution of crude prevalence percentage for
different response levels (“Poor”, “Fair”, “Good”, “Very good”,
“Excellent”), among different counties of Ny State.

``` r
library("patchwork")

plot_2006 = brfss_data %>%
  filter(
    year == "2006",
    locationabbr == "NY"
  ) %>%
  group_by(locationdesc, response) %>%
  summarize(
    mean_value = mean(data_value)
  ) %>% 
  ggplot(aes(x = response, y = mean_value, color = locationdesc, group = locationdesc)) +
  geom_point(alpha = .5) +
  geom_line() +
  labs(
    title = "Distribution of Crude Prevalence in NY Counties - 2006",
    x = "Response Level",
    y = "Crude Prevalence (%)",
    caption = NULL
  ) +
  guides(color = FALSE, size = FALSE)


plot_2010 = brfss_data %>%
  filter(
    year == "2010",
    locationabbr == "NY"
  ) %>%
  group_by(locationdesc, response) %>%
  summarize(
    mean_value = mean(data_value)
  ) %>% 
  ggplot(aes(x = response, y = mean_value, color = locationdesc, group = locationdesc)) +
  geom_point(alpha = .5) +
  geom_line() +
  labs(
    title = "Distribution of Crude Prevalence in NY Counties - 2010",
    x = "Response Level",
    y = "Crude Prevalence (%)",
    caption = NULL
  ) +
  theme(legend.position = "bottom")


(plot_2006 / plot_2010)
```

<img src="p8105_hw3_ha2546_files/figure-gfm/panel_plot-1.png" width="90%" />

## Problem 3

``` r
accel_data = read_csv("./data/accel_data.csv") 
```

    ## Parsed with column specification:
    ## cols(
    ##   .default = col_double(),
    ##   day = col_character()
    ## )

    ## See spec(...) for full column specifications.

``` r
accel_data_tidy = accel_data %>% 
  janitor::clean_names() %>% 
  pivot_longer(
    cols = activity_1:activity_1440,
    names_to = "activity_number",
    values_to = "value",
    names_prefix = "activity_"
  ) %>%
  select(activity_number, week, day, day_id, value) %>% 
  mutate(
    is_weekend = (day == "Saturday" | day == "Sunday")
  )

accel_data_tidy
```

    ## # A tibble: 50,400 x 6
    ##    activity_number  week day    day_id value is_weekend
    ##    <chr>           <dbl> <chr>   <dbl> <dbl> <lgl>     
    ##  1 1                   1 Friday      1  88.4 FALSE     
    ##  2 2                   1 Friday      1  82.2 FALSE     
    ##  3 3                   1 Friday      1  64.4 FALSE     
    ##  4 4                   1 Friday      1  70.0 FALSE     
    ##  5 5                   1 Friday      1  75.0 FALSE     
    ##  6 6                   1 Friday      1  66.3 FALSE     
    ##  7 7                   1 Friday      1  53.8 FALSE     
    ##  8 8                   1 Friday      1  47.8 FALSE     
    ##  9 9                   1 Friday      1  55.5 FALSE     
    ## 10 10                  1 Friday      1  43.0 FALSE     
    ## # ... with 50,390 more rows

DESCRIBE IT

``` r
total_activity_table = accel_data_tidy %>% 
  group_by(day_id) %>% 
  summarise(
    total_activity = sum(value)
  )

total_activity_plot = total_activity_table %>% 
  ggplot(aes(x = day_id, y = total_activity)) +
  geom_point() + 
  geom_line()

total_activity_table
```

    ## # A tibble: 35 x 2
    ##    day_id total_activity
    ##     <dbl>          <dbl>
    ##  1      1        480543.
    ##  2      2         78828.
    ##  3      3        376254 
    ##  4      4        631105 
    ##  5      5        355924.
    ##  6      6        307094.
    ##  7      7        340115.
    ##  8      8        568839 
    ##  9      9        295431 
    ## 10     10        607175 
    ## # ... with 25 more rows

``` r
total_activity_plot
```

<img src="p8105_hw3_ha2546_files/figure-gfm/unnamed-chunk-5-1.png" width="90%" />
Describe Trends

``` r
activity_day_amount = accel_data_tidy %>% 
  mutate(
    activity_number = as.numeric(as.character(activity_number))
  ) %>% 
  group_by(day, activity_number) %>% 
  summarize(
    mean_activity_day = mean(value)
  ) %>% 
  ggplot(aes(x = activity_number, y = mean_activity_day, color = day, group = day)) +
  geom_smooth(se = FALSE) +
  labs(
    title = "Average Activity over 24 hours for Each Day",
    x = "Time Course (hours)",
    y = "Average Activity Amount",
    caption = "Measured over 5 weeks"
  ) +
  scale_x_discrete(limit = c(240, 480, 720, 960, 1200, 1440),
                   labels = c("4", "8", "12", "16", "20", "24"))

activity_day_amount
```

    ## `geom_smooth()` using method = 'gam' and formula 'y ~ s(x, bs = "cs")'

<img src="p8105_hw3_ha2546_files/figure-gfm/unnamed-chunk-6-1.png" width="90%" />
