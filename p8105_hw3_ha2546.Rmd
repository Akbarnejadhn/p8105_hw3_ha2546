---
title: "p8105_hw3_ha2546"
author: "Hana Akbarnejad"
date: "10/9/2019"
output: github_document
---

```{r setup, include=FALSE}

library(tidyverse)
library(viridis)
library(ggridges)

knitr::opts_chunk$set(
  echo = TRUE,
  warning = FALSE,
  fig.width = 8,
  fig.height = 6,
  out.width = "90%"
  )

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)
scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
theme_set(theme_classic())
```

```{r Prob1_a}

library(p8105.datasets)
data("instacart")

instacart_desc = instacart %>% 
  filter(
    order_id == 112
  )
```

In the first problem, we are interested in exploring the _instacart_ dataset. This dataset stores information about online grocery shopping in 2017. The datset contains `r nrow(instacart)` observations of `r n_distinct(pull(instacart, order_id))` unique orders of `r n_distinct(pull(instacart, product_name))` differennt products. There are `r ncol(instacart)` variables associated with these rows such as _order_dow_ (the day of the week that the order has been placed), _order_hour_of_day_ (the time of the day that the order has been placed), _product_name_ (the item purchased), _aisle_ (the aisle that the item has chosen from), etc. For example, we can see that ordere with _order_id_ 112 contained `r nrow(instacart_desc)` items including `r head(pull(instacart_desc, product_name), 3)` from `r head(pull(instacart_desc, department), 3)` departments. These products has been chosen from aisles `r head(pull(instacart_desc, aisle_id), 3)` which are associated with the `r head(pull(instacart_desc, aisle), 3)` aisles, respectively. This order has been placed on Thursday at `r head(pull(instacart_desc, order_hour_of_day), 1)`, and `r head(pull(instacart_desc, days_since_prior_order), 1)` days after the pripr order of this customer (with the customer ID: `r head(pull(instacart_desc, user_id), 1)`).

## Problem1

How many aisles are there, and which aisles are the most items ordered from?
I grouped the dtaset by the aisles, and understood that there are total of 134 different isles. Then I counted the number of times items have been ordered from each isle. By further arranging this column in descending order, I found the most popular isles. Top five aisles with the most items ordered from are fresh vegetables, fresh fruits, packaged vegetable fruits, yogurt, packaged cheese.I then made a plot that shows the number of items ordered in each aisle (only for aisles with more than 10000 items ordered). For this purpose I made a bar plot that shows the aisle names on x axis and the number of items ordered on y axis.


```{r instacart}

aisle_fav_n = instacart %>% 
  # group_by(aisle) %>% 
  count(aisle, name = "aisle_order_n") %>% 
  arrange(desc(aisle_order_n))

aisle_fav_plot = aisle_fav_n %>% 
  filter(aisle_order_n > 10000) %>% 
  ggplot(aes(x = reorder(aisle, -aisle_order_n), y = aisle_order_n)) +
  geom_bar(stat="identity", width=0.5, fill="blue") +
  theme(axis.text.x = element_text(angle = 80, hjust = 1)) +
  labs(
    title = "Number of Orders in Favorite Aisles",
    x = "Aisle name",
    y = "Number of orders",
    caption = "Plot 1"
  )

aisle_fav_n
aisle_fav_plot
```



```{r}

top3_items = instacart %>% 
  filter(aisle == c("baking ingredients", "dog food care", "packaged vegetables fruits")) %>% 
  group_by(aisle, product_name) %>%
  summarize(
    count = n()
    ) %>% 
  top_n(3, count) %>% 
  knitr::kable()
```

In this part,

```{r}
hours_days_products = instacart %>% 
  filter(product_name == c("Pink Lady Apples", "Coffee Ice Cream")) %>% 
  group_by(product_name, order_dow) %>% 
  summarize(
    hours_mean = mean(order_hour_of_day)
  ) %>% 
  pivot_wider(
    names_from = order_dow,
    values_from = hours_mean
  ) %>%
    rename(
      Sun = `0`, Mon = `1`, Tue = `2`, Wed = `3`, Thr = `4`, Fri = `5`, Sat = `6`
      ) %>% 
  knitr::kable(digits = 1)
```

## Problem 2

In this part, I worked with _BRFSS_ dataset. First, I cleaned the names and made a subset of the data which is focused on the _Overall Health_, then I transformed response levels as ordered factors from poor to excellent.

```{r problem2_a}

data("brfss_smart2010") 

brfss_data = brfss_smart2010 %>% 
  janitor::clean_names() %>% 
  filter(topic == "Overall Health") %>% 
  mutate(
    response = factor(response, levels = c("Poor", "Fair", "Good", "Very good", "Excellent"), ordered = TRUE)
  )
```

On the next step, I needed to know which states has more or equal than 7 locations in both 2002 and 20010.

```{r}
brfss_location_2002 = brfss_data %>%
  filter(year == "2002") %>% 
  group_by(locationabbr) %>% 
  summarize(
    distinct_location = n_distinct(locationdesc)
    ) %>% 
  filter(distinct_location >= 7)


brfss_location_2010 = brfss_data %>%
  filter(year == "2010") %>% 
  group_by(locationabbr) %>% 
  summarize(
    distinct_location = n_distinct(locationdesc)
    ) %>% 
  filter(distinct_location >= 7)
```

We observed that during 2002, there were `r nrow(brfss_location_2002)` locations satissfying this condition, and during 2010 this number was `r nrow(brfss_location_2010)`.

In this part, I made a subset of data from excellent responses, then I summarized the mean of the data_value variable in different US states and then made a spagetti plot that shows the mean of crude prevalence percentage ( _data_value_ ) against different years.
```{r}

  brfss_exc = brfss_data %>%
  filter(
    response == "Excellent"
  ) %>%
  group_by(locationabbr, year) %>%
  summarize(
    mean_exc_location = mean(data_value)
  )

brfss_exc_spagetti = brfss_exc %>% 
  ggplot(aes(x = year, y = mean_exc_location, color = locationabbr)) +
  geom_line() +
    labs(
    title = "Average Crude Prevalence 2002 - 2010 among US States",
    x = "Year",
    y = "Average Crude Prevalence (%)",
    caption = "From BRFSS Excellent Responses")

brfss_exc_spagetti + labs(color = "STATES")

```

In this part, I made a panel plot for the data from 2006 and 2010, focusing on the distribution of crude prevalence percentage for different response levels ("Poor", "Fair", "Good", "Very good", "Excellent"), among different counties of Ny State. 
```{r panel_plot}

library("patchwork")

plot_2006 = brfss_data %>%
  filter(
    year == "2006",
    locationabbr == "NY"
  ) %>%
  group_by(locationdesc, response) %>%
  summarize(
    mean_value = mean(data_value)
  ) %>% 
  ggplot(aes(x = response, y = mean_value, color = locationdesc, group = locationdesc)) +
  geom_point(alpha = .5) +
  geom_line() +
  labs(
    title = "Distribution of Crude Prevalence in NY Counties - 2006",
    x = "Response Level",
    y = "Crude Prevalence (%)",
    caption = NULL
  ) +
  guides(color = FALSE, size = FALSE)


plot_2010 = brfss_data %>%
  filter(
    year == "2010",
    locationabbr == "NY"
  ) %>%
  group_by(locationdesc, response) %>%
  summarize(
    mean_value = mean(data_value)
  ) %>% 
  ggplot(aes(x = response, y = mean_value, color = locationdesc, group = locationdesc)) +
  geom_point(alpha = .5) +
  geom_line() +
  labs(
    title = "Distribution of Crude Prevalence in NY Counties - 2010",
    x = "Response Level",
    y = "Crude Prevalence (%)",
    caption = NULL
  ) +
  theme(legend.position = "bottom")


(plot_2006 / plot_2010)
```

## Problem 3
```{r prob3_load}
accel_data = read_csv("./data/accel_data.csv") 

accel_data_tidy = accel_data %>% 
  janitor::clean_names() %>% 
  pivot_longer(
    cols = activity_1:activity_1440,
    names_to = "activity_number",
    values_to = "value",
    names_prefix = "activity_"
  ) %>%
  select(activity_number, week, day, day_id, value) %>% 
  mutate(
    is_weekend = (day == "Saturday" | day == "Sunday")
  )

accel_data_tidy
```
 DESCRIBE IT
 
```{r}

total_activity_table = accel_data_tidy %>% 
  group_by(day_id) %>% 
  summarise(
    total_activity = sum(value)
  )

total_activity_plot = total_activity_table %>% 
  ggplot(aes(x = day_id, y = total_activity)) +
  geom_point() + 
  geom_line()

total_activity_table
total_activity_plot
```
Describe Trends

```{r}

activity_day_amount = accel_data_tidy %>% 
  mutate(
    activity_number = as.numeric(as.character(activity_number))
  ) %>% 
  group_by(day, activity_number) %>% 
  summarize(
    mean_activity_day = mean(value)
  ) %>% 
  ggplot(aes(x = activity_number, y = mean_activity_day, color = day, group = day)) +
  geom_smooth(se = FALSE) +
  labs(
    title = "Average Activity over 24 hours for Each Day",
    x = "Time Course (hours)",
    y = "Average Activity Amount",
    caption = "Measured over 5 weeks"
  ) +
  scale_x_discrete(limit = c(240, 480, 720, 960, 1200, 1440),
                   labels = c("4", "8", "12", "16", "20", "24"))

activity_day_amount
```

