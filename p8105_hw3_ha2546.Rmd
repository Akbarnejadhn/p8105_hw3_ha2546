---
title: "p8105_hw3_ha2546"
author: "Hana Akbarnejad"
date: "10/9/2019"
output: github_document
---

```{r setup, include=FALSE}

library(tidyverse)
library(viridis)
library(ggridges)

knitr::opts_chunk$set(
  echo = TRUE,
  warning = FALSE,
  fig.width = 8,
  fig.height = 6,
  out.width = "90%"
  )

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)
scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
theme_set(theme_classic())
# theme(legend.position = "bottom"))

library(p8105.datasets)
data("instacart")
```

```{r random_sample}

# set.seed(5)
# random_sample = instacart %>% 
#   filter(
#   sample(pull(instacart, order_id))
#   )

```

In the first problem, we are interested in exploring the _instacart_ dataset. This dataset stores information about online grocery shopping from 2017. The datset contains `r nrow(instacart)` observations of `r n_distinct(pull(instacart, order_id))` unique orders of `r n_distinct(pull(instacart, product_name))` differennt products. There are `r ncol(instacart)` variables associated with these rows such as _order_dow_ (the day of the week that the order has been placed), _order_hour_of_day_ (the time of the day that the order has been placed), _product_name_ (the item purchased), _aisle_ (the aisle that the item has chosen from), etc. We can take differenvt samples from this dataset.

## Problem1

How many aisles are there, and which aisles are the most items ordered from?
I grouped the dtaset by the aisles, and understood that there are total of 134 different isles. Then I counted the number of times items have been ordered from each isle. By further arranging this column in descending order, I found the most popular isles. Top five aisles with the most items ordered from are fresh vegetables, fresh fruits, packaged vegetable fruits, yogurt, packaged cheese.I then made a plot that shows the number of items ordered in each aisle (only for aisles with more than 10000 items ordered). For this purpose I made a bar plot that shows the aisle names on x axis and the number of items ordered on y axis.


```{r instacart}

aisle_fav_n = instacart %>% 
  # group_by(aisle) %>% 
  count(aisle, name = "aisle_order_n") %>% 
  arrange(desc(aisle_order_n))

aisle_fav_plot = aisle_fav_n %>% 
  filter(aisle_order_n > 10000) %>% 
  ggplot(aes(x = reorder(aisle, -aisle_order_n), y = aisle_order_n)) +
  geom_bar(stat="identity", width=0.5, fill="blue") +
  theme(axis.text.x = element_text(angle = 80, hjust = 1)) +
  labs(
    title = "Number of Orders in Favorite Aisles",
    x = "Aisle name",
    y = "Number of orders",
    caption = "Plot 1"
  )

aisle_fav_n
aisle_fav_plot
```



```{r}

top3_items = instacart %>% 
  filter(aisle == c("baking ingredients", "dog food care", "packaged vegetables fruits")) %>% 
  group_by(aisle, product_name) %>%
  summarize(
    count = n()
    ) %>% 
  top_n(3, count) %>% 
  knitr::kable()
```

In this part,

```{r}
hours_days_products = instacart %>% 
  filter(product_name == c("Pink Lady Apples", "Coffee Ice Cream")) %>% 
  group_by(product_name, order_dow) %>% 
  summarize(
    hours_mean = mean(order_hour_of_day)
  ) %>% 
  pivot_wider(
    names_from = order_dow,
    values_from = hours_mean
  ) %>%
    rename(
      Sun = `0`, Mon = `1`, Tue = `2`, Wed = `3`, Thr = `4`, Fri = `5`, Sat = `6`
      ) %>% 
  knitr::kable(digits = 1)
```

## Problem 2

In this part, I worked with _BRFSS_ dataset. First, I cleaned the names and made a subset of the data which is focused on the _Overall Health_, then I transformed response levels as ordered factors from poor to excellent.

```{r problem2_a}

data("brfss_smart2010") 

brfss_data = brfss_smart2010 %>% 
  janitor::clean_names() %>% 
  filter(topic == "Overall Health") %>% 
  mutate(
    response = factor(response, levels = c("Poor", "Fair", "Good", "Very good", "Excellent"), ordered = TRUE)
  )
```

On the next step, I needed to know which states has more or equal than 7 locations in both 2002 and 20010.

```{r}
brfss_location_2002 = brfss_data %>%
  filter(year == "2002") %>% 
  group_by(locationabbr) %>% 
  summarize(
    distinct_location = n_distinct(locationdesc)
    ) %>% 
  filter(distinct_location >= 7)


brfss_location_2010 = brfss_data %>%
  filter(year == "2010") %>% 
  group_by(locationabbr) %>% 
  summarize(
    distinct_location = n_distinct(locationdesc)
    ) %>% 
  filter(distinct_location >= 7)
```

We observed that during 2002, there were `r nrow(brfss_location_2002)` locations satissfying this condition, and during 2010 this number was `r nrow(brfss_location_2010)`.

In this part, I made a subset of data from excellent responses, then I summarized the mean of the data_value variable in different US states and then made a spagetti plot of the mean crude prevalence percentage (_data_value_) against different years.
```{r}

  brfss_exc = brfss_data %>%
  filter(
    response == "Excellent"
  ) %>%
  group_by(locationabbr, year) %>%
  summarize(
    mean_exc_location = mean(data_value)
  )

brfss_exc_spagetti = brfss_exc %>% 
  ggplot(aes(x = year, y = mean_exc_location, color = locationabbr)) +
  geom_line() +
    labs(
    title = "Mean Prevalence 2002 - 2010 among US States",
    x = "Year",
    y = "Mean Prevalence (%)",
    caption = "From BRFSS Excellent Responses")

brfss_exc_spagetti + labs(color = "STATES")

```


 2010, distribution of data_value for responses (“Poor” to “Excellent”) among locations in NY State
```{r}
library("patchwork")

graph_2006 = brfss_data %>%
  filter(
    year == "2006",
    locationabbr == "NY"
  ) %>%
  group_by(locationdesc) %>%
  ggplot(aes(x = response, y = data_value)) +
  geom_point(aes(color = locationdesc), alpha = .5) +
  geom_line()
  labs(
    title = "Distribution of Data Values - 2006",
    x = "Response Level",
    y = "Data Value",
    caption = NULL
  ) +
  theme_classic() +
  theme(legend.position = "bottom")



graph_2010 = brfss_data %>%
  filter(
    year == "2010",
    locationabbr == "NY"
  ) %>%
  group_by(locationdesc) %>%
  ggplot(aes(x = response, y = data_value)) +
  geom_bar(stat="identity", width=0.5, aes(color = response), alpha = .5) +
  labs(
    title = "Distribution of Data Values-2010",
    x = "Response Level",
    y = "Data Value",
    caption = NULL
  ) +
  facet_grid(. ~ locationdesc)
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  theme(legend.position = "bottom")


(graph_2006 / graph_2010)


```

## Problem 3
```{r}

```

